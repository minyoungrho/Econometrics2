{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling GLM [38e38edf-8417-5370-95a0-9cbb8c7f171a]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    }
   ],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using GLM\n",
    "using Optim\n",
    "using Statistics\n",
    "using ForwardDiff\n",
    "using NLopt\n",
    "using StatsFuns\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Nerlove Model\n",
    "\n",
    "### Theoretical Background\n",
    "For a firm that takes input prices $w$ and the output level $q$\n",
    "as given, the cost minimization problem is to choose the quantities\n",
    "of inputs $x$ to solve the problem\n",
    "$$\n",
    "\\min_{x}w'x\n",
    "$$\n",
    " subject to the restriction\n",
    "$$\n",
    "f(x)=q.\n",
    "$$\n",
    " The solution is the vector of factor demands $x(w,q)$. The cost\n",
    "function is obtained by substituting the factor demands into the\n",
    "criterion function: \n",
    "$$\n",
    "C(w,q)=w'x(w,q).\n",
    "$$\n",
    " \n",
    "- **Monotonicity** Increasing factor prices cannot decrease cost, so \n",
    "$$\\frac{\\partial C(w,q)}{\\partial w}\\geq0$$\n",
    "Remember that these derivatives give the conditional factor demands\n",
    "(Shephard's Lemma).\n",
    "- **Homogeneity** The cost function is homogeneous of degree 1 in input prices: $C(tw,q)=tC(w,q)$ where $t$ is a scalar constant. This is because the factor demands are homogeneous of degree zero in factor prices - they only depend upon relative prices.\n",
    "- **Returns to scale** The returns to scale parameter $\\gamma$ is defined as the inverse of the elasticity of cost with respect to output:\n",
    "$$\n",
    "\\gamma=\\left(\\frac{\\partial C(w,q)}{\\partial q}\\frac{q}{C(w,q)}\\right)^{-1}\n",
    "$$\n",
    "Constant returns to scale is the case where increasing production\n",
    "$q$ implies that cost increases in the proportion 1:1. If this is\n",
    "the case, then $\\gamma=1$.\n",
    "\n",
    "#### Cobb-Douglas functional form\n",
    "\n",
    "The Cobb-Douglas functional form is linear in the logarithms of the\n",
    "regressors and the dependent variable. For a cost function, if there\n",
    "are $g$ factors, the Cobb-Douglas cost function has the form\n",
    "\n",
    "$$\n",
    "C=Aw_{1}^{\\beta_{1}}...w_{g}^{\\beta_{g}}q^{\\beta_{q}}e^{\\varepsilon}\n",
    "$$\n",
    "What is the elasticity of $C$ with respect to $w_{j}$?\n",
    "\\begin{eqnarray*}\n",
    "e_{w_{j}}^{C} & = & \\left(\\frac{\\partial C}{\\partial_{W_{J}}}\\right)\\left(\\frac{w_{j}}{C}\\right)\\\\\n",
    " & = & \\beta_{j}Aw_{1}^{\\beta_{1}}.w_{j}^{\\beta_{j}-1}..w_{g}^{\\beta_{g}}q^{\\beta_{q}}e^{\\varepsilon}\\frac{w_{j}}{Aw_{1}^{\\beta_{1}}...w_{g}^{\\beta_{g}}q^{\\beta_{q}}e^{\\varepsilon}}\\\\\n",
    " & = & \\beta_{j}\n",
    "\\end{eqnarray*}\n",
    "This is one of the reasons the Cobb-Douglas form is popular - the\n",
    "coefficients are easy to interpret, since they are the elasticities\n",
    "of the dependent variable with respect to the explanatory variable.\n",
    "Not that in this case,\n",
    "\\begin{eqnarray*}\n",
    "e_{w_{j}}^{C} & = & \\left(\\frac{\\partial C}{\\partial_{W_{J}}}\\right)\\left(\\frac{w_{j}}{C}\\right)\\\\\n",
    " & = & x_{j}(w,q)\\frac{w_{j}}{C}\\\\\n",
    " & \\equiv & s_{j}(w,q)\n",
    "\\end{eqnarray*}\n",
    "the cost share of the $j^{th}$ input. So with a Cobb-Douglas\n",
    "cost function, $\\beta_{j}=s_{j}(w,q)$. The cost shares are constants.\n",
    "\n",
    "Note that after a logarithmic transformation we obtain\n",
    "$$\n",
    "\\ln C=\\alpha+\\beta_{1}\\ln w_{1}+...+\\beta_{g}\\ln w_{g}+\\beta_{q}\\ln q+\\epsilon\n",
    "$$\n",
    "where $\\alpha=\\ln A$ . So we see that the transformed model is linear\n",
    "in the logs of the data.\n",
    "\n",
    "One can verify that the property of HOD1 implies that \n",
    "$$\n",
    "\\sum_{i=1}^{g}\\beta_{i}=1\n",
    "$$\n",
    "In other words, the cost shares add up to 1. \n",
    "\n",
    "The hypothesis that the technology exhibits CRTS implies that \n",
    "$$\n",
    "\\gamma=\\frac{1}{\\beta_{q}}=1\n",
    "$$\n",
    "so $\\beta_{q}=1.$ Likewise, monotonicity implies that the coefficients\n",
    "$\\beta_{i}\\geq0,i=1,...,g$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Nerlove Data\n",
    "The file contains data on 145 electric utility companies' cost of production,\n",
    "output and input prices. The data are for the U.S., and were collected\n",
    "by M. Nerlove. The observations are by row, and the columns are \n",
    "- COMPANYCOST $(C)$\n",
    "- OUTPUT $(Q)$ \n",
    "- PRICE OF LABOR $(P_{L})$\n",
    "- PRICE OF FUEL $(P_{F})$\n",
    "- PRICE OF CAPITAL$(P_{K})$ \n",
    "\n",
    "Note that the data are sorted by output level (the third column).\n",
    "\n",
    "We will estimate the Cobb-Douglas model \n",
    "$$\\ln C=\\beta_{1}+\\beta_{Q}\\ln Q+\\beta_{L}\\ln P_{L}+\\beta_{F}\\ln P_{F}+\\beta_{K}\\ln P_{K}+\\epsilon\\label{simple nerlove model}\n",
    "$$ by OLS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>firm</th><th>cost</th><th>output</th><th>labor</th><th>fuel</th><th>capital</th></tr><tr><th></th><th>Int64</th><th>Float64</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Int64</th></tr></thead><tbody><p>6 rows × 6 columns</p><tr><th>1</th><td>101</td><td>0.082</td><td>2</td><td>2.09</td><td>17.9</td><td>183</td></tr><tr><th>2</th><td>102</td><td>0.661</td><td>3</td><td>2.05</td><td>35.1</td><td>174</td></tr><tr><th>3</th><td>103</td><td>0.99</td><td>4</td><td>2.05</td><td>35.1</td><td>171</td></tr><tr><th>4</th><td>104</td><td>0.315</td><td>4</td><td>1.83</td><td>32.2</td><td>166</td></tr><tr><th>5</th><td>105</td><td>0.197</td><td>5</td><td>2.12</td><td>28.6</td><td>233</td></tr><tr><th>6</th><td>106</td><td>0.098</td><td>9</td><td>2.12</td><td>28.6</td><td>195</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& firm & cost & output & labor & fuel & capital\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Float64 & Int64 & Float64 & Float64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 101 & 0.082 & 2 & 2.09 & 17.9 & 183 \\\\\n",
       "\t2 & 102 & 0.661 & 3 & 2.05 & 35.1 & 174 \\\\\n",
       "\t3 & 103 & 0.99 & 4 & 2.05 & 35.1 & 171 \\\\\n",
       "\t4 & 104 & 0.315 & 4 & 1.83 & 32.2 & 166 \\\\\n",
       "\t5 & 105 & 0.197 & 5 & 2.12 & 28.6 & 233 \\\\\n",
       "\t6 & 106 & 0.098 & 9 & 2.12 & 28.6 & 195 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m6×6 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m firm  \u001b[0m\u001b[1m cost    \u001b[0m\u001b[1m output \u001b[0m\u001b[1m labor   \u001b[0m\u001b[1m fuel    \u001b[0m\u001b[1m capital \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64   \u001b[0m\n",
       "─────┼───────────────────────────────────────────────────\n",
       "   1 │   101    0.082       2     2.09     17.9      183\n",
       "   2 │   102    0.661       3     2.05     35.1      174\n",
       "   3 │   103    0.99        4     2.05     35.1      171\n",
       "   4 │   104    0.315       4     1.83     32.2      166\n",
       "   5 │   105    0.197       5     2.12     28.6      233\n",
       "   6 │   106    0.098       9     2.12     28.6      195"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DataFrame(CSV.File(\"../data/nerlove.csv\"))\n",
    "first(data,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>cost</th><th>output</th><th>labor</th><th>fuel</th><th>capital</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>6 rows × 5 columns</p><tr><th>1</th><td>-2.50104</td><td>0.693147</td><td>0.737164</td><td>2.8848</td><td>5.20949</td></tr><tr><th>2</th><td>-0.414001</td><td>1.09861</td><td>0.71784</td><td>3.5582</td><td>5.15906</td></tr><tr><th>3</th><td>-0.0100503</td><td>1.38629</td><td>0.71784</td><td>3.5582</td><td>5.14166</td></tr><tr><th>4</th><td>-1.15518</td><td>1.38629</td><td>0.604316</td><td>3.47197</td><td>5.11199</td></tr><tr><th>5</th><td>-1.62455</td><td>1.60944</td><td>0.751416</td><td>3.35341</td><td>5.45104</td></tr><tr><th>6</th><td>-2.32279</td><td>2.19722</td><td>0.751416</td><td>3.35341</td><td>5.273</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& cost & output & labor & fuel & capital\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & -2.50104 & 0.693147 & 0.737164 & 2.8848 & 5.20949 \\\\\n",
       "\t2 & -0.414001 & 1.09861 & 0.71784 & 3.5582 & 5.15906 \\\\\n",
       "\t3 & -0.0100503 & 1.38629 & 0.71784 & 3.5582 & 5.14166 \\\\\n",
       "\t4 & -1.15518 & 1.38629 & 0.604316 & 3.47197 & 5.11199 \\\\\n",
       "\t5 & -1.62455 & 1.60944 & 0.751416 & 3.35341 & 5.45104 \\\\\n",
       "\t6 & -2.32279 & 2.19722 & 0.751416 & 3.35341 & 5.273 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m6×5 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m cost       \u001b[0m\u001b[1m output   \u001b[0m\u001b[1m labor    \u001b[0m\u001b[1m fuel    \u001b[0m\u001b[1m capital \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64    \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\n",
       "─────┼──────────────────────────────────────────────────\n",
       "   1 │ -2.50104    0.693147  0.737164  2.8848   5.20949\n",
       "   2 │ -0.414001   1.09861   0.71784   3.5582   5.15906\n",
       "   3 │ -0.0100503  1.38629   0.71784   3.5582   5.14166\n",
       "   4 │ -1.15518    1.38629   0.604316  3.47197  5.11199\n",
       "   5 │ -1.62455    1.60944   0.751416  3.35341  5.45104\n",
       "   6 │ -2.32279    2.19722   0.751416  3.35341  5.273"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = log.(data[:,[:cost,:output,:labor,:fuel,:capital]])\n",
    "first(data,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145×5 Array{Float64,2}:\n",
       " 1.0  0.693147  0.737164  2.8848   5.20949\n",
       " 1.0  1.09861   0.71784   3.5582   5.15906\n",
       " 1.0  1.38629   0.71784   3.5582   5.14166\n",
       " 1.0  1.38629   0.604316  3.47197  5.11199\n",
       " 1.0  1.60944   0.751416  3.35341  5.45104\n",
       " 1.0  2.19722   0.751416  3.35341  5.273\n",
       " 1.0  2.3979    0.683097  3.56953  5.32788\n",
       " 1.0  2.56495   0.71784   3.5582   5.01064\n",
       " 1.0  2.56495   0.783902  3.37074  5.04343\n",
       " 1.0  3.09104   0.542324  2.70805  5.23644\n",
       " 1.0  3.21888   0.737164  2.8848   5.1358\n",
       " 1.0  3.21888   0.518794  3.68135  5.11799\n",
       " 1.0  3.55535   0.593327  3.11795  5.36129\n",
       " ⋮                                 \n",
       " 1.0  8.72193   0.652325  3.11352  5.07517\n",
       " 1.0  8.88086   0.751416  3.35341  5.0876\n",
       " 1.0  8.97284   0.476234  2.8792   5.18178\n",
       " 1.0  9.03825   0.841567  3.46261  5.2933\n",
       " 1.0  9.06439   0.806476  3.27714  5.20401\n",
       " 1.0  9.08103   0.837248  3.51155  5.24702\n",
       " 1.0  9.15736   0.746688  3.19458  5.10595\n",
       " 1.0  9.20593   0.518794  3.36038  5.31321\n",
       " 1.0  9.3481    0.806476  3.27714  5.01728\n",
       " 1.0  9.37552   0.751416  3.35341  4.99721\n",
       " 1.0  9.57213   0.837248  3.51155  5.35659\n",
       " 1.0  9.7243    0.832909  3.16125  5.0876"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = size(data,1)\n",
    "y = data[:,1]\n",
    "x = data[:,2:end]\n",
    "x[!,:intercept]=ones(size(data,1))\n",
    "x = x[!,[:intercept,:output,:labor,:fuel,:capital]]\n",
    "\n",
    "y = convert(Array,y)\n",
    "x = convert(Array,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " -3.5265028449802216\n",
       "  0.7203940758797012\n",
       "  0.4363412007892406\n",
       "  0.4265169530627446\n",
       " -0.2198883507567723"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv(x'*x)*x'*y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Array{Float64,1}},GLM.DensePredChol{Float64,LinearAlgebra.CholeskyPivoted{Float64,Array{Float64,2}}}},Array{Float64,2}}\n",
       "\n",
       "cost ~ 1 + output + labor + fuel + capital\n",
       "\n",
       "Coefficients:\n",
       "──────────────────────────────────────────────────────────────────────────\n",
       "                 Coef.  Std. Error      t  Pr(>|t|)  Lower 95%   Upper 95%\n",
       "──────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)  -3.5265     1.77437    -1.99    0.0488  -7.03452   -0.0184845\n",
       "output        0.720394   0.0174664  41.24    <1e-79   0.685862   0.754926\n",
       "labor         0.436341   0.291048    1.50    0.1361  -0.139076   1.01176\n",
       "fuel          0.426517   0.100369    4.25    <1e-4    0.228082   0.624952\n",
       "capital      -0.219888   0.339429   -0.65    0.5182  -0.890957   0.45118\n",
       "──────────────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols = lm(@formula(cost~output+labor+fuel+capital),data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fminunc (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fminunc(obj, x; tol = 1e-08)\n",
    "results = Optim.optimize(obj, x, LBFGS(),\n",
    "Optim.Options(\n",
    "g_tol = tol,\n",
    "x_tol=tol,\n",
    "f_tol=tol))\n",
    "return results.minimizer, results.minimum, Optim.converged(results)\n",
    "#xopt, objvalue, flag = fmincon(obj, x, tol=tol)\n",
    "#return xopt, objvalue, flag\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function normal(theta, y, x)\n",
    "b = theta[1:end-1]\n",
    "s = theta[end][1]\n",
    "e = (y - x*b)./s\n",
    "logdensity = -log.(sqrt.(2.0*pi)) .- 0.5*log(s.^2) .- 0.5*e.*e\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mle (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mle(model, θ)\n",
    "    avg_obj = θ -> -mean(vec(model(θ))) # average log likelihood\n",
    "    thetahat, objvalue, converged = fminunc(avg_obj, θ) # do the minimization of -logL\n",
    "    objvalue = -objvalue\n",
    "    obj = θ -> vec(model(θ)) # unaveraged log likelihood\n",
    "    n = size(obj(θ),1) # how many observations?\n",
    "    scorecontrib = ForwardDiff.jacobian(obj, vec(thetahat))\n",
    "    I = cov(scorecontrib)\n",
    "    J = ForwardDiff.hessian(avg_obj, vec(thetahat))\n",
    "    Jinv = inv(J)\n",
    "    V= Jinv*I*Jinv/n\n",
    "    return thetahat, objvalue, V, converged\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-3.5265029527984506, 0.7203941307911956, 0.4363410601373892, 0.4265167999256887, -0.21988830342608368, 0.3855314736645991], -0.4658061612351275, [2.871544188031368 -0.013350664827278202 … -0.5341833292561572 0.00758992898888696; -0.01335066482727622 0.0010330820163605126 … 0.0014703347896175387 -0.000888618606090073; … ; -0.5341833292561352 0.0014703347896179168 … 0.10194167672632491 -0.0009345831820626936; 0.00758992898888676 -0.000888618606090018 … -0.0009345831820626361 0.0017343512126735234], true)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = [zeros(size(x,2)); 1.0] # start values for estimation\n",
    "model = theta -> normal(theta, y, x)\n",
    "thetahat, objvalue, V, converged = mle(model, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Float64,1}:\n",
       " -3.5265029527984506\n",
       "  0.7203941307911956\n",
       "  0.4363410601373892\n",
       "  0.4265167999256887\n",
       " -0.21988830342608368\n",
       "  0.3855314736645991"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetahat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4658061612351275"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmm (generic function with 1 method)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gmm(moments, theta, weight)\n",
    "    # average moments\n",
    "    m = theta -> vec(mean(moments(theta),dims=1)) # 1Xg\n",
    "    # moment contributions\n",
    "    momentcontrib = theta -> moments(theta) # nXg\n",
    "    # GMM criterion\n",
    "    obj = theta -> ((m(theta))'weight*m(theta))\n",
    "    # do minimization\n",
    "    thetahat, objvalue, converged = fminunc(obj, theta)\n",
    "    # derivative of average moments\n",
    "    D = (ForwardDiff.jacobian(m, vec(thetahat)))' \n",
    "    # moment contributions at estimate\n",
    "    ms = momentcontrib(thetahat)\n",
    "    return thetahat, objvalue, D, ms, converged\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-3.526502843629834, 0.7203940758779137, 0.4363412007234413, 0.4265169530669924, -0.21988835101027032], 2.0315912495823984e-25, [-1.0 -6.556651068379128 … -3.2088584232140143 -5.15677677573767; -6.556651068379128 -46.62321518989734 … -20.92418272643975 -33.79234977799892; … ; -3.2088584232140143 -20.92418272643975 … -10.424693444784769 -16.552050639682335; -5.15677677573767 -33.79234977799892 … -16.552050639682335 -26.60235530942714], [0.11956154515690232 0.08287374792889741 … 0.3449112306976858 0.622854213907207; 1.6246276007326357 1.7848358466742609 … 5.780751765522584 8.38154363280989; … ; 0.8830924883738982 8.453078045568063 … 3.1010193996152986 4.730361102489577; 0.7151025229149148 6.953872233201762 … 2.260615499330251 3.6381529748973525], true)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = 1\n",
    "theta = zeros(size(x,2))\n",
    "moments = theta -> (y .- x*theta).*x\n",
    "thetahat1, junk, junk, ms, junk = gmm(moments, theta, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " -3.526502843629834\n",
       "  0.7203940758779137\n",
       "  0.4363412007234413\n",
       "  0.4265169530669924\n",
       " -0.21988835101027032"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetahat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-3.526502845237955, 0.7203940758869178, 0.43634120077645283, 0.42651695306397513, -0.21988835071590623], 4.523502175795952e-22, [-1.0 -6.556651068379128 … -3.2088584232140143 -5.15677677573767; -6.556651068379128 -46.62321518989734 … -20.92418272643975 -33.79234977799892; … ; -3.2088584232140143 -20.92418272643975 … -10.424693444784769 -16.552050639682335; -5.15677677573767 -33.79234977799892 … -16.552050639682335 -26.60235530942714], [0.11956154519492257 0.08287374795525106 … 0.34491123080736663 0.6228542141052729; 1.6246276007849059 1.7848358467316856 … 5.7807517657085725 8.381543633079556; … ; 0.8830924882852536 8.453078044719545 … 3.1010193993040187 4.730361102014744; 0.7151025229032566 6.953872233088394 … 2.2606154992933964 3.63815297483804], true)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = inv(cov(ms))\n",
    "thetahat2, junk, junk, ms, junk = gmm(moments, theta, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " -3.526502845237955\n",
       "  0.7203940758869178\n",
       "  0.43634120077645283\n",
       "  0.42651695306397513\n",
       " -0.21988835071590623"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetahat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted Nerlove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fminunc"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    xopt, fopt, converged = fminunc(obj, startval)\n",
    "\n",
    "Minimize the function obj, starting at startval.\n",
    "\n",
    "fminunc() with no arguments will run an example, execute edit(fminunc,()) to see the code.\n",
    "fminunc() uses NLopt.jl  to do the actual minimization.\n",
    "\n",
    "\"\"\"\n",
    "function fminunc(obj, x; tol = 1e-10)\n",
    "    results = Optim.optimize(obj, x, LBFGS(), \n",
    "                            Optim.Options(\n",
    "                            g_tol = tol,\n",
    "                            x_tol=tol,\n",
    "                            f_tol=tol))\n",
    "    return results.minimizer, results.minimum, Optim.converged(results)\n",
    "    #xopt, objvalue, flag = fmincon(obj, x, tol=tol)\n",
    "    #return xopt, objvalue, flag\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-3.526502845286827, 0.7203940758804234, 0.4363412008175227, 0.4265169530531963, -0.21988835069604426], 21.55200816418578, true)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the objective function and start value\n",
    "obj = theta -> (y-x*theta)'*(y-x*theta)\n",
    "startval = [-1e6, -1e6, 0., 0., 0.0]\n",
    "\n",
    "# OLS\n",
    "thetahat, objvalue = fminunc(obj, startval) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fmincon"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    xopt, fopt, converged = fmincon(obj, startval)\n",
    "\n",
    "Minimize the function obj, starting at startval.\n",
    "\n",
    "fminunc() with no arguments will run an example, execute edit(fminunc,()) to see the code.\n",
    "fminunc() uses NLopt.jl to do the actual minimization.\n",
    "\n",
    "\"\"\"\n",
    "function fmincon(obj, startval, R=[], r=[], lb=[], ub=[]; tol = 1e-25, iterlim=0)\n",
    "    # the objective is an anonymous function\n",
    "    function objective_function(x::Vector{Float64}, grad::Vector{Float64})\n",
    "        obj_func_value = obj(x)[1,1]\n",
    "        return(obj_func_value)\n",
    "    end\n",
    "    # impose the linear restrictions\n",
    "    function constraint_function(x::Vector, grad::Vector, R, r)\n",
    "        result = R*x .- r\n",
    "        return result[1,1]\n",
    "    end\n",
    "    opt = Opt(:LN_COBYLA, size(startval,1))\n",
    "    min_objective!(opt, objective_function)\n",
    "    # impose lower and/or upper bounds\n",
    "    if lb != [] lower_bounds!(opt, lb) end\n",
    "    if ub != [] upper_bounds!(opt, ub) end\n",
    "    # impose linear restrictions, by looping over the rows\n",
    "    if R != []\n",
    "        for i = 1:size(R,1)\n",
    "            equality_constraint!(opt, (theta, g) -> constraint_function(theta, g, R[i:i,:], r[i]), tol)\n",
    "        end\n",
    "    end    \n",
    "    xtol_rel!(opt, tol)\n",
    "    ftol_rel!(opt, tol)\n",
    "    maxeval!(opt, iterlim)\n",
    "    (objvalue, xopt, flag) = NLopt.optimize(opt, startval)\n",
    "    return xopt, objvalue, flag\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-6.048596329679246, 0.7206760132410218, 0.3250348901994794, 0.33416246746988226, 0.34080264233063823], 22.20823582015495, :XTOL_REACHED)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bounds and restriction\n",
    "lb = [-1e6, -1e6, 0., 0., 0.0]\n",
    "ub = [1e6, 1e6, 1., 1., 1.]\n",
    "R = [0. 0. 1. 1. 1.]\n",
    "r = 1.0\n",
    "\n",
    "# restricted LS\n",
    "thetahat, objvalue_r, flag = fmincon(obj, startval, R, r, lb, ub) # both lower and upper bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(thetahat[3:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the review purpose, please refer to [this notes](https://web.stanford.edu/~mrosenfe/soc_meth_proj3/matrix_OLS_NYU_notes.pdf) for OLS in Matrix Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general formulation of linear equality restrictions is the model\n",
    "\\begin{eqnarray*}\n",
    "y & = & X\\beta+\\varepsilon\\\\\n",
    "R\\beta & = & r\n",
    "\\end{eqnarray*}\n",
    " where $R$ is a $Q\\times K$ matrix, $Q<K$ and $r$ is a $Q\\times1$\n",
    "vector of constants.\n",
    "\n",
    "Let's consider how to estimate $\\beta$ subject to the restrictions\n",
    "$R\\beta=r.$ The most obvious approach is to set up the Lagrangean\n",
    "$$\n",
    "\\min_{\\beta,\\lambda}s(\\beta,\\lambda)=\\frac{1}{n}\\left(y-X\\beta\\right)^{\\prime}\\left(y-X\\beta\\right)+2\\lambda^{\\prime}(R\\beta-r).\n",
    "$$\n",
    " The Lagrange multipliers are scaled by 2, which makes things less\n",
    "messy. The fonc are \n",
    "\\begin{eqnarray*}\n",
    "D_{\\beta}s(\\hat{\\beta},\\hat{\\lambda}) & = & -2X^{\\prime}y+2X^{\\prime}X\\hat{\\beta}_{R}+2R^{\\prime}\\hat{\\lambda}\\equiv0\\\\\n",
    "D_{\\lambda}s(\\hat{\\beta},\\hat{\\lambda}) & = & R\\hat{\\beta}_{R}-r\\equiv0,\n",
    "\\end{eqnarray*}\n",
    "\n",
    "which can be written as \n",
    "$$\n",
    "\\left[\\begin{array}{cc}\n",
    "X^{\\prime}X & R^{\\prime}\\\\\n",
    "R & 0\n",
    "\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "\\hat{\\beta}_{R}\\\\\n",
    "\\hat{\\lambda}\n",
    "\\end{array}\\right]=\\left[\\begin{array}{c}\n",
    "X^{\\prime}y\\\\\n",
    "r\n",
    "\\end{array}\\right].\n",
    "$$\n",
    " Re-arragne: \n",
    "$$\n",
    "\\left[\\begin{array}{c}\n",
    "\\hat{\\beta}_{R}\\\\\n",
    "\\hat{\\lambda}\n",
    "\\end{array}\\right]=\\left[\\begin{array}{cc}\n",
    "X^{\\prime}X & R^{\\prime}\\\\\n",
    "R & 0\n",
    "\\end{array}\\right]^{-1}\\left[\\begin{array}{c}\n",
    "X^{\\prime}y\\\\\n",
    "r\n",
    "\\end{array}\\right].\n",
    "$$\n",
    "\n",
    "and define that $P=R\\left(X^{\\prime}X\\right)^{-1}R^{\\prime}$:\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\left[\\begin{array}{c}\n",
    "\\hat{\\beta}_{R}\\\\\n",
    "\\hat{\\lambda}\n",
    "\\end{array}\\right] & = & \\left[\\begin{array}{cc}\n",
    "\\left(X^{\\prime}X\\right)^{-1}-(X^{\\prime}X)^{-1}R^{\\prime}P^{-1}R\\left(X^{\\prime}X\\right)^{-1} & (X^{\\prime}X)^{-1}R^{\\prime}P^{-1}\\\\\n",
    "P^{-1}R\\left(X^{\\prime}X\\right)^{-1} & -P^{-1}\n",
    "\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "X^{\\prime}y\\\\\n",
    "r\n",
    "\\end{array}\\right]\\\\\n",
    " & = & \\left[\\begin{array}{c}\n",
    "\\hat{\\beta}-(X^{\\prime}X)^{-1}R^{\\prime}P^{-1}\\left(R\\hat{\\beta}-r\\right)\\\\\n",
    "P^{-1}\\left(R\\hat{\\beta}-r\\right)\n",
    "\\end{array}\\right]\\\\\n",
    " & = & \\left[\\begin{array}{c}\n",
    "\\left(I_{K}-(X^{\\prime}X)^{-1}R^{\\prime}P^{-1}R\\right)\\\\\n",
    "P^{-1}R\n",
    "\\end{array}\\right]\\hat{\\beta}+\\left[\\begin{array}{c}\n",
    "(X^{\\prime}X)^{-1}R^{\\prime}P^{-1}r\\\\\n",
    "-P^{-1}r\n",
    "\\end{array}\\right]\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "The fact that $\\hat{\\beta}_{R}$ and $\\hat{\\lambda}$ are linear\n",
    "functions of $\\hat{\\beta}$ makes it easy to determine their distributions,\n",
    "since the distribution of $\\hat{\\beta}$ is already known. Recall\n",
    "that for $x$ a random vector, and for $A$ and $b$ a matrix and\n",
    "vector of constants, respectively, $Var\\left(Ax+b\\right)=AVar(x)A^{\\prime}.$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ols (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ols(y::Array{Float64}, x::Array{Float64,2}; R=[], r=[], vc=\"white\", silent=false)\n",
    "        \n",
    "    # compute ols coefficients, fitted values, and errors\n",
    "    function lsfit(y, x)\n",
    "        beta = inv(x'*x)*x'*y\n",
    "        fit = x*beta\n",
    "        errors = y - fit\n",
    "        return beta, fit, errors\n",
    "    end\n",
    "\n",
    "    n,k = size(x)\n",
    "    b, fit, e = lsfit(y,x)\n",
    "    df = n-k\n",
    "    sigsq = (e'*e/df)[1,1]\n",
    "    xx_inv = inv(x'*x)\n",
    "    ess = (e' * e)[1,1]\n",
    "    \n",
    "    # Restricted LS\n",
    "    if R !=[]\n",
    "        q = size(R,1)\n",
    "        P_inv = inv(R*xx_inv*R')\n",
    "        b = b .- xx_inv*R'*P_inv*(R*b.-r)\n",
    "        e = y-x*b;\n",
    "        ess = (e' * e)[1,1]\n",
    "        df = n-k-q\n",
    "        sigsq = ess/df\n",
    "        A = Matrix{Float64}(I, k, k) .- xx_inv*R'*P_inv*R;  # the matrix relating b and b_r\n",
    "    end\n",
    "\n",
    "    xe = x.*e\n",
    "    varb = xx_inv*xe'xe*xx_inv\n",
    "\n",
    "    # restricted LS?\n",
    "    if R !=[]\n",
    "        varb = A*varb*A'\n",
    "    end\n",
    "\n",
    "    # common to both ordinary and restricted\n",
    "    seb = sqrt.(diag(varb))\n",
    "    seb = seb.*(seb.>1e-16) # round off to zero when there are restrictions\n",
    "    t = b ./ seb\n",
    "    tss = y .- mean(y)\n",
    "    tss = (tss'*tss)[1,1]\n",
    "    rsq = (1.0 - ess / tss)\n",
    "    \n",
    "    p = 2.0 .- 2.0*tdistcdf.(df, abs.(t))\n",
    "\n",
    "    return b, seb, t, p\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's decompose the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lsfit (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lsfit(y, x)\n",
    "    beta = inv(x'*x)*x'*y\n",
    "    fit = x*beta\n",
    "    errors = y - fit\n",
    "    return beta, fit, errors\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.55200816418577"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,k = size(x)\n",
    "b, fit, e = lsfit(y,x)\n",
    "df = n-k\n",
    "sigsq = (e'*e/df)[1,1]\n",
    "xx_inv = inv(x'*x)\n",
    "ess = (e' * e)[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1539429154584698"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(e'*e/df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set restrictions:\n",
    "R = [0 0 1 1 1]\n",
    "r = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Array{Float64,2}:\n",
       " 1.0  0.0   3.26103       3.26103       3.26103\n",
       " 0.0  1.0  -0.000821913  -0.000821913  -0.000821913\n",
       " 0.0  0.0   0.56147      -0.43853      -0.43853\n",
       " 0.0  0.0   0.033738      1.03374       0.033738\n",
       " 0.0  0.0  -0.595208     -0.595208      0.404792"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If restricted:\n",
    "q = size(R,1)\n",
    "P_inv = inv(R*xx_inv*R')\n",
    "b = b .- xx_inv*R'*P_inv*(R*b.-r)\n",
    "e = y-x*b;\n",
    "ess = (e' * e)[1,1]\n",
    "df = n-k-q\n",
    "sigsq = ess/df\n",
    "A = Matrix{Float64}(I, k, k) .- xx_inv*R'*P_inv*R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Array{Float64,2}:\n",
       "  2.79541    -0.0124238    -0.139666     0.0235275    -0.522476\n",
       " -0.0124238   0.00102379   -0.00145555  -0.000238609   0.00131859\n",
       " -0.139666   -0.00145555    0.060153    -0.00876526    0.0270589\n",
       "  0.0235275  -0.000238609  -0.00876526   0.00560044   -0.00651251\n",
       " -0.522476    0.00131859    0.0270589   -0.00651251    0.100198"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xe = x.*e\n",
    "varb = xx_inv*xe'xe*xx_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Array{Float64,2}:\n",
       "  0.645676    -0.0136316     0.125187    -0.00872577   -0.116461\n",
       " -0.0136316    0.00102454   -0.00128702  -0.000248581   0.0015356\n",
       "  0.125187    -0.00128702    0.0277956   -0.0046787    -0.0231169\n",
       " -0.00872577  -0.000248581  -0.0046787    0.00516317   -0.000484464\n",
       " -0.116461     0.0015356    -0.0231169   -0.000484464   0.0236014"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If restricted:\n",
    "varb = A*varb*A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9256517157418225"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seb = sqrt.(diag(varb))\n",
    "seb = seb.*(seb.>1e-16) # round off to zero when there are restrictions\n",
    "t = b ./ seb\n",
    "tss = y .- mean(y)\n",
    "tss = (tss'*tss)[1,1]\n",
    "rsq = (1.0 - ess / tss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, estimate with restricted OLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-4.690789123000792, 0.7206875237539881, 0.592909608392978, 0.4144714553168333, -0.007381063709811425], [0.8035399132401216, 0.03200841460252987, 0.16672022985133889, 0.07185518151252615, 0.15362745919807486], [-5.837655411647293, 22.515564507122658, 3.5563147251036287, 5.768149861879906, -0.048045211112258755], [3.568130679809656e-8, 0.0, 0.0005147311810049793, 4.981561319006289e-8, 0.9617491746445415])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b, seb, t, p) = ols(y, x, R=R, r=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " -4.690789123000792\n",
       "  0.7206875237539881\n",
       "  0.592909608392978\n",
       "  0.4144714553168333\n",
       " -0.007381063709811425"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " 0.8035399132401216\n",
       " 0.03200841460252987\n",
       " 0.16672022985133889\n",
       " 0.07185518151252615\n",
       " 0.15362745919807486"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " 3.568130679809656e-8\n",
       " 0.0\n",
       " 0.0005147311810049793\n",
       " 4.981561319006289e-8\n",
       " 0.9617491746445415"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(b[3:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Statistics: Linear Models with Restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wald Statistic\n",
    "Recall that wald test statistic:\n",
    "$$W\\equiv n\\bf{a}(\\hat{\\theta})'\n",
    "\\big[\\bf{A}(\\hat{\\theta})\\hat{\\Sigma}^{-1}\\bf{A}(\\hat{\\theta})'\\big]^{-1}\\bf{a}(\\hat{\\theta})$$\n",
    "is asymptotically $\\chi^2(r)$ under the null hypothesis.\n",
    "\n",
    "The $t$ and $F$ tests require normality of the errors. The Wald\n",
    "test does not, but it is an asymptotic test - it is only approximately\n",
    "valid in finite samples.\n",
    "\n",
    "The Wald principle is based on the idea that if a restriction is true,\n",
    "the unrestricted model should ``approximately'' satisfy the restriction.\n",
    "Given that the least squares estimator is asymptotically normally\n",
    "distributed: \n",
    "$$\n",
    "\\sqrt{n}\\left(\\hat{\\beta}-\\beta_{0}\\right)\\overset{d}{\\rightarrow}N\\left(0,\\sigma_{0}^{2}Q_{X}^{-1}\\right)\n",
    "$$\n",
    " then under $H_{0}:R\\beta_{0}=r,$ we have \n",
    "$$\n",
    "\\sqrt{n}\\left(R\\hat{\\beta}-r\\right)\\overset{d}{\\rightarrow}N\\left(0,\\sigma_{0}^{2}RQ_{X}^{-1}R^{\\prime}\\right)\n",
    "$$\n",
    " because if the $n$ dimensional\n",
    "random vector $x\\sim N(0,V),$ then $x^{\\prime}V^{-1}x\\sim\\chi^{2}(n).$\n",
    "$$\n",
    "n\\left(R\\hat{\\beta}-r\\right)^{\\prime}\\left(\\sigma_{0}^{2}RQ_{X}^{-1}R^{\\prime}\\right)^{-1}\\left(R\\hat{\\beta}-r\\right)\\overset{d}{\\rightarrow}\\chi^{2}(q)\n",
    "$$\n",
    " Note that $Q_{X}^{-1}$ or $\\sigma_{0}^{2}$ are not observable.\n",
    "The test statistic we use substitutes the consistent estimators. Use\n",
    "$(X^{\\prime}X/n)^{-1}$ as the consistent estimator of $Q_{X}^{-1}.$\n",
    "With this, there is a cancellation of $n^{\\prime}s,$ and the statistic\n",
    "to use is \n",
    "$$\n",
    "\\left(R\\hat{\\beta}-r\\right)^{\\prime}\\left(\\widehat{\\sigma_{0}^{2}}R(X^{\\prime}X)^{-1}R^{\\prime}\\right)^{-1}\\left(R\\hat{\\beta}-r\\right)\\overset{d}{\\rightarrow}\\chi^{2}(q)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,k = size(x)\n",
    "q = size(R,1)\n",
    "b = x\\y\n",
    "xx_inv = inv(x'*x)\n",
    "P_inv = inv(R*xx_inv*R')\n",
    "b_r = b .- xx_inv*R'*P_inv*(R*b.-r)\n",
    "e = y - x*b\n",
    "ess = (e'*e)[1]\n",
    "e_r = y - x*b_r\n",
    "ess_r = (e_r' * e_r)[1]\n",
    "sigsqhat = ess/(n)\n",
    "sigsqhat_r = ess_r/(n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5941482584878846"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = (R*b.-r)'*P_inv*(R*b.-r)/sigsqhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44081948121548903"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chisqccdf(q,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood Ratio Multiplier (LR) Statistic\n",
    "\n",
    "Reference Hayashi 7.4 for details on derivations.\n",
    "\n",
    "\n",
    "$$\\begin{align}\n",
    "LR &\\equiv 2n\\big[ Q_n(\\hat{\\theta}) - Q_n(\\tilde{\\theta}) \\big] \\\\\n",
    "& = -n(\\hat{\\theta}-\\tilde{\\theta})'\\Psi(\\hat{\\theta}-\\tilde{\\theta}) + o_p\\\\\n",
    "% & = n\\gamma'_n \\big[\\bf{A}(\\hat{\\theta})\\hat{\\Sigma}^{-1}\\bf{A}(\\hat{\\theta})'\\big] \\gamma_n\n",
    "\\end{align}$$\n",
    "is asymptotically $\\chi^2(r)$ under the null hypothesis.\n",
    "\n",
    "From this expression, deriving the asymptotic distribution of the LR:\n",
    "$$ \\sqrt{n}(\\hat{\\theta}-\\tilde{\\theta}) = -\\Psi^{-1}A'_0(A_0\\Psi^{-1}A'_0)^{-1}A_0'\\Psi^{-1}\\sqrt{n}\\frac{\\partial Q_n(\\theta_0)}{\\partial \\theta}+o_p\n",
    "$$\n",
    "\n",
    "Substituting the above equation to LR statistics and setting $\\sqrt{n}\\frac{\\partial Q_n(\\theta_0)}{\\partial \\theta} = g(\\theta_{0})$ and $\\Psi^{-1} = \\mathcal{I}(\\theta_{0})$ \n",
    "\n",
    "\\begin{equation}\n",
    "LR\\overset{a}{=}n^{1/2}g(\\theta_{0})^{\\prime}\\mathcal{I}(\\theta_{0})^{-1}R^{\\prime}\\left(R\\mathcal{I}(\\theta_{0})^{-1}R^{\\prime}\\right)^{-1}R\\mathcal{I}(\\theta_{0})^{-1}n^{1/2}g(\\theta_{0})\\label{eq:LR}\n",
    "\\end{equation}\n",
    " Under normality, we have seen that the likelihood function is \n",
    "$$\n",
    "\\ln L(\\beta,\\sigma)=-n\\ln\\sqrt{2\\pi}-n\\ln\\sigma-\\frac{1}{2}\\frac{\\left(y-X\\beta\\right)^{\\prime}\\left(y-X\\beta\\right)}{\\sigma^{2}}.\n",
    "$$\n",
    " Using this, \n",
    "\\begin{eqnarray*}\n",
    "g(\\beta_{0}) & \\equiv & D_{\\beta}\\frac{1}{n}\\ln L(\\beta,\\sigma)\\\\\n",
    " & = & \\frac{X^{\\prime}(y-X\\beta_{0})}{n\\sigma^{2}}\\\\\n",
    " & = & \\frac{X^{\\prime}\\varepsilon}{n\\sigma^{2}}\n",
    "\\end{eqnarray*}\n",
    " Also, by the information matrix equality: \n",
    "\\begin{eqnarray*}\n",
    "\\mathcal{I}(\\theta_{0}) & = & -H_{\\infty}(\\theta_{0})\\\\\n",
    " & = & \\lim-D_{\\beta^{\\prime}}g(\\beta_{0})\\\\\n",
    " & = & \\lim-D_{\\beta^{\\prime}}\\frac{X^{\\prime}(y-X\\beta_{0})}{n\\sigma^{2}}\\\\\n",
    " & = & \\lim\\frac{X^{\\prime}X}{n\\sigma^{2}}\\\\\n",
    " & = & \\frac{Q_{X}}{\\sigma^{2}}\n",
    "\\end{eqnarray*}\n",
    " so \n",
    "$$\n",
    "\\mathcal{I}(\\theta_{0})^{-1}=\\sigma^{2}Q_{X}^{-1}\n",
    "$$\n",
    " Substituting these last expressions:\n",
    "\\begin{eqnarray*}\n",
    "LR & \\overset{a}{=} & \\varepsilon^{\\prime}X^{\\prime}(X^{\\prime}X)^{-1}R^{\\prime}\\left(\\sigma_{0}^{2}R(X^{\\prime}X)^{-1}R^{\\prime}\\right)^{-1}R(X^{\\prime}X)^{-1}X^{\\prime}\\varepsilon\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5929342902877579"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnl = -n/2*log(2*pi) - n/2*log(sigsqhat) - ess/(2.0*sigsqhat)\n",
    "lnl_r = -n/2*log(2*pi) - n/2*log(sigsqhat_r) - ess_r/(2.0*sigsqhat_r)\n",
    "LR = 2.0*(lnl-lnl_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44128668478235494"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chisqccdf.(q,LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Lagrange Multiplier (LM) Statistic\n",
    "$$\\begin{align}\n",
    "LM &\\equiv n\\bigg(\\frac{\\partial Q_n(\\tilde{\\theta})}{\\partial \\theta}\\bigg)' \\tilde{\\Sigma}^{-1} \\bigg(\\frac{\\partial Q_n(\\tilde{\\theta})}{\\partial \\theta}\\bigg) \\\\\n",
    "% & = n\\gamma'_n \\big[\\bf{A}(\\hat{\\theta})\\hat{\\Sigma}^{-1}\\bf{A}(\\hat{\\theta})'\\big] \\gamma_n\n",
    "\\end{align}$$\n",
    "is asymptotically $\\chi^2(r)$ under the nuull hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that \n",
    "\\begin{eqnarray*}\n",
    "\\hat{\\lambda} & = & \\left(R(X^{\\prime}X)^{-1}R^{\\prime}\\right)^{-1}\\left(R\\hat{\\beta}-r\\right)\\\\\n",
    " & = & P^{-1}\\left(R\\hat{\\beta}-r\\right)\n",
    "\\end{eqnarray*}\n",
    "so\n",
    "$$\n",
    "\\sqrt{n}\\hat{P\\lambda}=\\sqrt{n}\\left(R\\hat{\\beta}-r\\right)\n",
    "$$\n",
    "Given that \n",
    "$$\n",
    "\\sqrt{n}\\left(R\\hat{\\beta}-r\\right)\\overset{d}{\\rightarrow}N\\left(0,\\sigma_{0}^{2}RQ_{X}^{-1}R^{\\prime}\\right)\n",
    "$$\n",
    " under the null hypothesis, we obtain \n",
    "$$\n",
    "\\sqrt{n}\\hat{P\\lambda}\\overset{d}{\\rightarrow}N\\left(0,\\sigma_{0}^{2}RQ_{X}^{-1}R^{\\prime}\\right)\n",
    "$$\n",
    " So\n",
    "$$\n",
    "\\left(\\sqrt{n}\\hat{P\\lambda}\\right)^{\\prime}\\left(\\sigma_{0}^{2}RQ_{X}^{-1}R^{\\prime}\\right)^{-1}\\left(\\sqrt{n}\\hat{P\\lambda}\\right)\\overset{d}{\\rightarrow}\\chi^{2}(q)\n",
    "$$\n",
    "Noting that $\\lim nP=RQ_{X}^{-1}R^{\\prime},$ we obtain, \n",
    "$$\n",
    "\\hat{\\lambda}^{\\prime}\\left(\\frac{R(X^{\\prime}X)^{-1}R^{\\prime}}{\\sigma_{0}^{2}}\\right)\\hat{\\lambda}\\overset{d}{\\rightarrow}\\chi^{2}(q)\n",
    "$$\n",
    " since the powers of $n$ cancel. To get a usable test statistic substitute\n",
    "a consistent estimator of $\\sigma_{0}^{2}.$\n",
    "\n",
    "This makes it clear why the test is sometimes referred to as a Lagrange\n",
    "multiplier test. It may seem that one needs the actual Lagrange multipliers\n",
    "to calculate this. If we impose the restrictions by substitution,\n",
    "these are not available. Note that the test can be written as \n",
    "$$\n",
    "\\frac{\\left(R^{\\prime}\\hat{\\lambda}\\right)^{\\prime}(X^{\\prime}X)^{-1}R^{\\prime}\\hat{\\lambda}}{\\sigma_{0}^{2}}\\overset{d}{\\rightarrow}\\chi^{2}(q)\n",
    "$$\n",
    " However, we can use the foc for the restricted estimator: \n",
    "$$\n",
    "-X^{\\prime}y+X^{\\prime}X\\hat{\\beta}_{R}+R^{\\prime}\\hat{\\lambda}\n",
    "$$\n",
    " to get that \n",
    "\\begin{eqnarray*}\n",
    "R^{\\prime}\\hat{\\lambda} & = & X^{\\prime}(y-X\\hat{\\beta}_{R})\\\\\n",
    " & = & X^{\\prime}\\hat{\\varepsilon}_{R}\n",
    "\\end{eqnarray*}\n",
    " Substituting this into the above, we get \n",
    "$$\n",
    "\\frac{\\hat{\\varepsilon}_{R}^{\\prime}X(X^{\\prime}X)^{-1}X^{\\prime}\\hat{\\varepsilon}_{R}}{\\sigma_{0}^{2}}\\overset{d}{\\rightarrow}\\chi^{2}(q)\n",
    "$$\n",
    " but this is simply \n",
    "$$\n",
    "\\hat{\\varepsilon}_{R}^{\\prime}\\frac{P_{X}}{\\sigma_{0}^{2}}\\hat{\\varepsilon}_{R}\\overset{d}{\\rightarrow}\\chi^{2}(q).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5917236270218078"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_x = x * xx_inv * x'\n",
    "S = e_r' * P_x * e_r/(sigsqhat_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4417533757921563"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chisqccdf(q,S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestStatistics (generic function with 1 method)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function TestStatistics(y, x, R, r; silent=false)\n",
    "    n,k = size(x)\n",
    "    q = size(R,1)\n",
    "    b = x\\y\n",
    "    xx_inv = inv(x'*x)\n",
    "    P_inv = inv(R*xx_inv*R')\n",
    "    b_r = b .- xx_inv*R'*P_inv*(R*b.-r)\n",
    "    e = y - x*b\n",
    "    ess = (e'*e)[1]\n",
    "    e_r = y - x*b_r\n",
    "    ess_r = (e_r' * e_r)[1]\n",
    "    sigsqhat = ess/(n)\n",
    "    sigsqhat_r = ess_r/(n)\n",
    "    # Wald test (uses unrestricted model's est. of sig^2)\n",
    "    W = (R*b.-r)'*P_inv*(R*b.-r)/sigsqhat\n",
    "    # LR test\n",
    "    lnl = -n/2*log(2*pi) - n/2*log(sigsqhat) - ess/(2.0*sigsqhat)\n",
    "    lnl_r = -n/2*log(2*pi) - n/2*log(sigsqhat_r) - ess_r/(2.0*sigsqhat_r)\n",
    "    LR = 2.0*(lnl-lnl_r)\n",
    "    # Score test (uses restricted model's est. of sig^2)\n",
    "    P_x = x * xx_inv * x'\n",
    "    S = e_r' * P_x * e_r/(sigsqhat_r)\n",
    "    \n",
    "    tests_label = [\"Wald\",\"LR\",\"LM\"]\n",
    "    tests = [W[1], LR[1], S[1]]\n",
    "    pvalues = chisqccdf.(q,tests)\n",
    "    \n",
    "    return tests_label, tests, pvalues\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"Wald\", \"LR\", \"LM\"], [0.5941482584878846, 0.5929342902877579, 0.5917236270218078], [0.44081948121548903, 0.44128668478235494, 0.4417533757921563])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestStatistics(y, x, R, r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Hence, $\\beta_{labor} + \\beta_{fuel} + \\beta_{capital} = 1$ is not rejected at the usual significance level. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.4",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
