{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: the following packages will be useful in solving this prolem set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Optim\n",
    "using Statistics\n",
    "using ForwardDiff\n",
    "using Plots\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2\n",
    "**Due: May 3, 2021** (in class; subject to change if COVID restrictions apply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binary response is a variable that takes on only two values, customarily\n",
    "0 and 1, which can be thought of as codes for whether or not a condisiton\n",
    "is satisfied. For example, 0=drive to work, 1=take the bus. Often\n",
    "the observed binary variable, say $y$, is related to an unobserved\n",
    "(latent) continuous varable, say $y^{*}$. We would like to know the\n",
    "effect of covariates, $x$, on $y.$ The model can be represented\n",
    "as \n",
    "\\begin{eqnarray*}\n",
    "y^{*} & = & g(x)-\\varepsilon\\\\\n",
    "y & = & 1(y^{*}>0)\\\\\n",
    "Pr(y=1) & = & F_{\\varepsilon}[g(x)]\\\\\n",
    " & \\equiv & p(x,\\theta)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "For the logit model, the probability has the specific form\n",
    "$$\n",
    "p(x,\\theta)=\\frac{1}{1+\\exp(-x^{\\prime}\\theta)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (MLE)\n",
    "\n",
    "We will consider maximum likelihood estimation of\n",
    "the logit model for binary 0/1 dependent variables. We will use the\n",
    "BFGS algorithm to find the MLE. \n",
    "\n",
    "The log-likelihood function is\n",
    "\n",
    "$$\n",
    "s_{n}(\\theta)=\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_{i}\\ln p(x_{i},\\theta)+(1-y_{i})\\ln\\left[1-p(x_{i},\\theta)\\right]\\right)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code generates that follow a logit model with given $\\theta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogitDGP (generic function with 1 method)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function LogitDGP(n, theta)\n",
    "    k = size(theta,1)\n",
    "    x = ones(n,1)\n",
    "    if k>1 \n",
    "        x = [x  randn(n,k-1)]\n",
    "    end\n",
    "    y = Float64.((1.0 ./ (1.0 .+ exp.(-x*theta)) .> rand(n,1)))\n",
    "    return y, x\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us estimate $\\hat{\\theta}$ from the dataset with 100 points ($n=100$) and generated from the true $\\theta$ ($\\theta_0$) value of $[0.5,0.5]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0; 1.0; … ; 0.0; 0.0], [1.0 -1.1194714896206426; 1.0 0.7907570846532597; … ; 1.0 -0.18735590485531636; 1.0 -1.340239374172393])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=100\n",
    "theta = [0.75,0.25]\n",
    "(y,x) = LogitDGP(n,theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1. a) Estimate $\\hat{\\theta}$.**\n",
    "\n",
    "Hint: \n",
    "\n",
    "1. Refer to [Nerlove lecture notes](https://github.com/minyoungrho/Econometrics2/blob/main/lectures/Nerlove.ipynb) for an example code for mle estimation.\n",
    "2. Code for the log likelihood function \n",
    "$$\n",
    "s_{n}(\\theta)=\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_{i}\\ln p(x_{i},\\theta)+(1-y_{i})\\ln\\left[1-p(x_{i},\\theta)\\right]\\right)\n",
    "$$\n",
    "is written as below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1. b) Empirically prove consistency of $\\hat{\\theta}$ by increasing the number of n in DGP and re-estimate.**\n",
    "\n",
    "Hint: Refer to [GMM lecture notes](https://github.com/minyoungrho/Econometrics2/blob/main/lectures/GMM.ipynb) for an example code for empirically proving consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1. c) Empirically prove asymptotic normality of $\\hat{\\theta}$ by repeatedly generate data.**\n",
    "\n",
    "\n",
    "Hint: Refer to [GMM lecture notes](https://github.com/minyoungrho/Econometrics2/blob/main/lectures/GMM.ipynb) for an example code for empirically proving asymptotic normality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (GMM)\n",
    "Recall from [GMM lecture notes](https://github.com/minyoungrho/Econometrics2/blob/main/lectures/GMM.ipynb):\n",
    "\n",
    "Suppose the model\n",
    "is \n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "y_{t}^{*} & = & \\alpha+\\rho y_{t-1}^{*}+\\beta x_{t}+\\epsilon_{t}\\\\\n",
    "y_{t} & = & y_{t}^{*}+\\upsilon_{t}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "where $\\epsilon_{t}$ and $\\upsilon_{t}$ are independent Gaussian\n",
    "white noise errors. Suppose that $y_{t}^{*}$ is not observed, and\n",
    "instead we observe $y_{t}$. If we estimate the equation \n",
    "$$\n",
    "y_{t}=\\alpha+\\rho y_{t-1}+\\beta x_{t}+\\nu_{t}\n",
    "$$\n",
    "this the estimator is biased and inconsistent. \n",
    "\n",
    "What about using the GIV\n",
    "estimator? \n",
    "\n",
    "Consider using as instruments $Z=\\left[1\\,x_{t}\\,x_{t-1}\\,x_{t-2}\\right]$.\n",
    "The lags of $x_{t}$ are correlated with $y_{t-1}$ as long as $\\beta$\n",
    "is different from zero, and by assumption $x_{t}$ and its lags are\n",
    "uncorrelated with $\\epsilon_{t}$ and $\\upsilon_{t}$ (and thus they're\n",
    "also uncorrelated with $\\nu_{t})$. Thus, these are legitimate instruments.\n",
    "As we have 4 instruments and 3 parameters, this is an overidentified\n",
    "situation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lags (generic function with 2 methods)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lag(x::Array{Float64,2},p::Int64)\n",
    "\tn,k = size(x)\n",
    "\tlagged_x = [ones(p,k); x[1:n-p,:]]\n",
    "end\n",
    "\n",
    "function lag(x::Array{Float64,1},p::Int64)\n",
    "\tn = size(x,1)\n",
    "\tlagged_x = [ones(p); x[1:n-p]]\n",
    "end\t \n",
    "\n",
    "\n",
    "function  lags(x::Array{Float64,2},p)\n",
    "\tn, k = size(x)\n",
    "\tlagged_x = zeros(eltype(x),n,p*k)\n",
    "\tfor i = 1:p\n",
    "\t\tlagged_x[:,i*k-k+1:i*k] = lag(x,i)\n",
    "\tend\n",
    "    return lagged_x\n",
    "end\t\n",
    "\n",
    "function  lags(x::Array{Float64,1},p)\n",
    "\tn = size(x,1)\n",
    "\tlagged_x = zeros(eltype(x), n,p)\n",
    "\tfor i = 1:p\n",
    "\t\tlagged_x[:,i] = lag(x,i)\n",
    "\tend\n",
    "    return lagged_x\n",
    "end\t "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Given $[\\alpha_0,\\rho_0,\\beta_0] = [0, 0.9, 1]$, let us generate data using the pre-defined  lag function above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.0\n",
       " 0.9\n",
       " 1.0"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100\n",
    "sig = 1\n",
    "\n",
    "x = randn(n) # an exogenous regressor\n",
    "e = randn(n) # the error term\n",
    "ystar = zeros(n)\n",
    "# generate the dep var\n",
    "for t = 2:n\n",
    "  ystar[t] = 0.0 + 0.9*ystar[t-1] + 1.0*x[t] + e[t]\n",
    "end\n",
    "# add measurement error\n",
    "y = ystar + sig*randn(n)\n",
    "ylag = lag(y,1)\n",
    "data = [y ylag x];\n",
    "data = data[2:end,:] # drop first obs, missing due to lag\n",
    "theta = [0, 0.9, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2. a) Given the following GIVmoments function, write down the moment conditions for each data point. In other words, write down $m_t(\\theta)$ $\\forall t$ where $t$ is an index for each data points and $\\bar{m_n}(\\theta)$.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GIVmoments (generic function with 1 method)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moment condition\n",
    "function GIVmoments(theta, data)\n",
    "\tdata = [data lags(data,2)]\n",
    "    data = data[3:end,:] # get rid of missings\n",
    "\tn = size(data,1)\n",
    "\ty = data[:,1]\n",
    "\tylag = data[:,2]\n",
    "\tx = data[:,3]\n",
    "\txlag = data[:,6]\n",
    "\txlag2 = data[:,9]\n",
    "\tX = [ones(n,1) ylag x]\n",
    "\te = y - X*theta\n",
    "\tZ = [ones(n,1) x xlag xlag2]\n",
    "\tm = e.*Z\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2. b) Calculate $\\hat{\\theta}$ using two step GMM.**\n",
    "\n",
    "Hint: use the following code to generate moment.\n",
    "\n",
    "Compare the estimates with the true parameter value: $[\\alpha_0,\\rho_0,\\beta_0] = [0, 0.9, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2. c) Empirically prove consistency of $\\hat{\\theta}$ from two step GMM by increasing the number of n in DGP and re-estimate.**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.4",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
